{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (4.47.0)\n",
      "Requirement already satisfied: torch in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: peft in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (0.14.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (1.4.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (3.3.1)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (0.45.2)\n",
      "Requirement already satisfied: streamlit in c:\\programdata\\anaconda3\\lib\\site-packages (1.37.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: watchdog<5,>=2.1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (4.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in c:\\programdata\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch peft accelerate datasets bitsandbytes streamlit tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (4.47.0)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (0.45.2)\n",
      "Requirement already satisfied: accelerate in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (1.4.0)\n",
      "Requirement already satisfied: peft in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: torch<3,>=2.0 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from bitsandbytes) (2.6.0+cu118)\n",
      "Requirement already satisfied: psutil in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from torch<3,>=2.0->bitsandbytes) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jay\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers bitsandbytes accelerate peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a45590b1464ddd9fb3efcec96f5db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "#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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"debate_model_finetuned\"\n",
    "device = \"mps\" if torch.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [24:43<00:00, 741.96s/it] \n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:24<00:00, 42.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLaMA-2-7B successfully loaded on mps (No bitsandbytes, using float16)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# âœ… Ensure MPS (Apple GPU) is available, otherwise fallback to CPU\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "MODEL_PATH = \"meta-llama/Llama-2-7b-chat-hf\"  # Change if needed\n",
    "\n",
    "# âœ… Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Fix padding issues\n",
    "\n",
    "# âŒ Remove bitsandbytes (not supported on macOS) âœ… Use float16 for MPS compatibility\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.float16,  # âœ… Use float16 instead of 4-bit quantization\n",
    "    device_map={\"\": device}  # âœ… Automatically assign layers to MPS or CPU\n",
    ")\n",
    "\n",
    "# âœ… Compile Model for Faster Execution (optional)\n",
    "model = torch.compile(model)\n",
    "\n",
    "print(f\"âœ… LLaMA-2-7B successfully loaded on {device} (No bitsandbytes, using float16)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ—£ï¸ LLaMA-2-7B Response:\n",
      " Debate Topic: Should AI be regulated?\n",
      "Position: Pro\n",
      "Stage: Opening\n",
      "Argument:\n",
      "\n",
      "Argument:\n",
      "we should regulate artificial intelligence .\n",
      "\n",
      "two arguments .\n",
      "\n",
      "the first is that the technology is so powerful that we need to protect people from the negative consequences of it .\n",
      "\n",
      "so we need to limit the power of the technology and ensure that it doesn't get out of hand .\n",
      "\n",
      "\n",
      "\n",
      "so we need to limit how it's used in society ,\n",
      "\n",
      "we need to limit how it's used in the workplace ,\n",
      "\n",
      "we\n"
     ]
    }
   ],
   "source": [
    "# Define a sample debate prompt\n",
    "test_prompt = \"Debate Topic: Should AI be regulated?\\nPosition: Pro\\nStage: Opening\\nArgument:\\n\"\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "\n",
    "# Generate response\n",
    "output_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=100, \n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# Decode output\n",
    "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(\"\\nðŸ—£ï¸ LLaMA-2-7B Response:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBATE_FORMATS = {\n",
    "    \"public_forum\": {\"roles\": [\"Pro\", \"Con\"], \"structure\": [\"Opening\", \"Rebuttal\", \"Summary\", \"Final Focus\"]},\n",
    "    \"team_debate\": {\"roles\": [\"Affirmative\", \"Negative\"], \"structure\": [\"Constructive\", \"Rebuttal\", \"Crossfire\"]},\n",
    "    \"policy_debate\": {\"roles\": [\"Affirmative\", \"Negative\"], \"structure\": [\"Plan\", \"Counterplan\", \"Rebuttal\"]}\n",
    "}\n",
    "\n",
    "debate_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_logical_fallacy(argument):\n",
    "    \"\"\"Detects logical fallacies in an argument.\"\"\"\n",
    "    prompt = f\"Analyze the following argument and detect any logical fallacies:\\n{argument}\\nProvide a response identifying any fallacy present.\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    output_ids = model.generate(inputs.input_ids, max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "def generate_argument(debate_format, topic, role, stage, opponent_argument=None):\n",
    "    \"\"\"Generates structured arguments and detects logical fallacies.\"\"\"\n",
    "    prompt = f\"Debate Format: {debate_format}\\nTopic: {topic}\\nRole: {role}\\nStage: {stage}\\n\"\n",
    "    \n",
    "    if stage == \"Rebuttal\" and opponent_argument:\n",
    "        prompt += f\"Opponent's Argument: {opponent_argument}\\nGenerate a rebuttal considering all previous arguments.\"\n",
    "    else:\n",
    "        prompt += \"Generate a structured argument for this stage.\"\n",
    "\n",
    "    if debate_history and stage == \"Rebuttal\":\n",
    "        prompt += \"\\nPrevious Arguments:\\n\" + \"\\n\".join(debate_history[-3:])  # Last 3 arguments for context\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    output_ids = model.generate(inputs.input_ids, max_new_tokens=150, pad_token_id=tokenizer.eos_token_id)\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Add generated argument to history\n",
    "    debate_history.append(f\"{role} ({stage}): {generated_text}\")\n",
    "\n",
    "    # Check logical fallacy\n",
    "    fallacy_check = check_logical_fallacy(generated_text)\n",
    "    return generated_text, fallacy_check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_feedback(response):\n",
    "    \"\"\"Ask user for feedback to improve AI responses.\"\"\"\n",
    "    print(\"\\nAI Response:\\n\", response)\n",
    "    feedback = input(\"Was this a good response? (yes/no): \").strip().lower()\n",
    "    return 1 if feedback == \"yes\" else -1  # 1 for good, -1 for bad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_debate():\n",
    "    \"\"\"Run the debate interactively with AI.\"\"\"\n",
    "    topic = input(\"Enter Debate Topic: \").strip()\n",
    "    debate_format = input(\"Choose Debate Format (public_forum/team_debate/policy_debate): \").strip()\n",
    "\n",
    "    role = \"Pro\"\n",
    "    stage = \"Opening\"\n",
    "\n",
    "    while True:\n",
    "        # AI generates argument\n",
    "        argument, fallacy = generate_argument(debate_format, topic, role, stage)\n",
    "        print(f\"\\n{role} ({stage}) Argument:\\n\", argument)\n",
    "        print(\"\\nLogical Fallacy Check:\\n\", fallacy)\n",
    "\n",
    "        # Get user feedback\n",
    "        feedback = get_user_feedback(argument)\n",
    "\n",
    "        # Swap roles for next round\n",
    "        role = \"Con\" if role == \"Pro\" else \"Pro\"\n",
    "        stage = \"Rebuttal\" if stage == \"Opening\" else \"Closing\"\n",
    "\n",
    "        # Stop after closing statements\n",
    "        if stage == \"Closing\":\n",
    "            break\n",
    "\n",
    "    print(\"\\nDebate Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
