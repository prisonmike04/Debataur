# ğŸ™ï¸ Debataur: AI-Powered Debating Platform

---

## ğŸ“– Introduction
The **AI-Powered Debating Platform** is designed to facilitate **intelligent, structured debates** between users and an **LLM-driven AI**. It is fine-tuned to generate persuasive, logical arguments and incorporates **real-time fact-checking** using **Wolfram Alpha** and **Wikipedia AI**.

The platform allows users to:
- Engage in **real-time** debates with AI.
- **Verify claims instantly** through live fact-checking.
- Evaluate AI-generated arguments based on logical reasoning, factual accuracy, and coherence.

---

## ğŸš€ Features
âœ”ï¸ **AI-Generated Arguments** â€“ The AI constructs logical arguments for and against a given motion.  
âœ”ï¸ **Real-Time Debate Simulation** â€“ Engage in structured debates with AI.  
âœ”ï¸ **Multi-Turn Debate Format** â€“ AI dynamically responds to user arguments.  
âœ”ï¸ **Fine-Tuned for Debate Quality** â€“ Models are trained on debate datasets.  
âœ”ï¸ **Bias Detection & Logical Coherence** â€“ AI evaluates biases in its own responses.  
âœ”ï¸ **Live Performance Metrics** â€“ AI rates responses based on logic and persuasiveness.  
âœ”ï¸ **Real-Time Fact Checking** â€“ Uses **Wolfram Alpha** and **Wikipedia AI** to verify claims.  

---

## ğŸ¯ Project Objective
- Develop an **AI-powered debating assistant** capable of generating persuasive and logical arguments.
- Fine-tune **LLaMA-2-7B** and **Falcon-7B** models for **debate-specific responses**.
- Ensure **factual consistency** using **real-time fact-checking tools**.
- Enable **multi-turn debates** with rebuttals and counterarguments.
- Evaluate **AI debate performance** using **customized metrics**.

---

## ğŸ§  Models Used
### ğŸ”¹ **Base Models**
- **LLaMA-2-7B** (Meta) â€“ Optimized for reasoning and factual correctness.
- **Falcon-7B** (TII) â€“ Suited for generating high-quality natural language responses.

### ğŸ”¹ **Fine-Tuning**
- **4-bit Quantization & CPU Offloading** for training efficiency.
- **LoRA & QLoRA** for parameter-efficient fine-tuning.
- **Gradient Checkpointing** to optimize memory usage.

---

## ğŸ“Š Dataset
- **Debate-Specific Dataset** from Kaggle and IBM.
- **Argument Quality Datasets** from AI2.
- **Political & Philosophical Debates** scraped from online sources.


---

## ğŸ”§ Fine-Tuning Process
1ï¸âƒ£ **Baseline Testing** â€“ Evaluate vanilla **LLaMA-2-7B** & **Falcon-7B** on debate prompts.  
2ï¸âƒ£ **Data Preprocessing** â€“ Tokenization, formatting, and prompt engineering.  
3ï¸âƒ£ **Fine-Tuning on Debate Datasets** â€“ Using **LoRA/QLoRA** for efficient training.  
4ï¸âƒ£ **Hyperparameter Tuning** â€“ Optimizing learning rates, batch sizes, and weight decay.  
5ï¸âƒ£ **Evaluation on Logical Consistency** â€“ Using custom-defined scoring metrics.  
6ï¸âƒ£ **Bias & Hallucination Control** â€“ Detecting factually incorrect or biased arguments.  

---

## ğŸ“ Evaluation Metrics
ğŸ“Œ **Logical Consistency Score (LCS)** â€“ Measures argument coherence.  
ğŸ“Œ **Factual Accuracy Score (FAS)** â€“ Uses **real-time fact-checking** for AI-generated claims.  
ğŸ“Œ **Bias Detection Score (BDS)** â€“ Identifies politically/socially biased arguments.  
ğŸ“Œ **Engagement Score (ES)** â€“ Evaluates AI's responsiveness in a debate.  

---

---

## ğŸ“¦ 2ï¸âƒ£ Install Dependencies

**pip install -r requirements.txt
**cd frontend && yarn install

## ğŸ”„ 3ï¸âƒ£ Run Backend
**cd backend
**python main.py

## ğŸŒ 4ï¸âƒ£ Start Frontend

**cd frontend
**yarn dev

